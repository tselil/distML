\documentclass[final]{beamer}
\mode<presentation>
{
  \usetheme{Szeged}
\usecolortheme{crane}
}


\usepackage{times}
\usepackage{multicol}
\usepackage{amsmath,amssymb,amsthm}

\newtheorem{alg}{Algorithm}

\newcommand{\argmax}{\text{argmax}}
\usepackage{float, caption, subcaption}
\usepackage[english]{babel}
\usepackage[latin1]{inputenc}
\usepackage{beamerposter}  % e.g. custom size poster
  \title[Hangman]{{\veryHuge Adversarial Hangman:\\ Learning and Exploiting a Human Player's Guessing Distribution}}
  \author[Schramm \& Weitz]{{\Large Tselil Schramm and Ben Weitz}}
\date{}

  \begin{document}
{\large
  \begin{frame}{} 

\maketitle

\vspace{-3cm}
\begin{center}
\begin{columns}[t]
\begin{column}{0.32\textwidth}

    \begin{block}{\huge Introduction}
\vspace{.4cm}
\begin{columns}[t]
\begin{column}{0.6\textwidth}
\begin{itemize}
\item Hangman is a word game with two players.
\begin{itemize} {\large
\item The first player chooses a word.
\item The second player tries to guess it by guessing letters with a fixed allowance of incorrect guesses.}
\end{itemize}

\vspace{.5cm}

\item {\bf Project Goal:} Develop Hangman AI that 
\begin{itemize} {\large
\item Learns the distribution of the human player's guesses.
\item Chooses words adversarially based on the learned distribution.\\}
\end{itemize}
\end{itemize}
\end{column}
\begin{column}{0.4\textwidth}
\begin{figure}
\includegraphics{hangman3.png}
\caption{A game of hangman.}
\end{figure}
\end{column}
\end{columns}
\vspace{.5cm}
\end{block}

\vspace{1.2cm}

    \begin{block}{\huge Model}
\vspace{.5cm}
{\Large Model the player using a Directed Graphical Model:}
\begin{itemize}
\item $X_t$ are the "Question Nodes" depend on previous guesses and answers
\item $Y_t$ are the "Response Nodes" depend only on $X_t$ and the hidden word
\end{itemize}
\begin{figure}
\includegraphics[width=0.4\textwidth]{modelkmemBoxed.pdf}
\caption{Our model of the human player's guessing distribution with full memory.}
\end{figure}
{\Large Remembering everything is computationally intractable.}
\begin{itemize}
\item Restrict model's memory to a finite lookback.
\item Memory ranges between $1$ and $3$ are relatively feasible. 
\end{itemize}
\begin{figure}
\includegraphics[width=0.4\textwidth]{model1memBoxed.pdf}
\caption{Our model of the human player's guessing distribution with memory limited to the previous turn.}
\end{figure}
    \end{block}
\vspace{1.2cm}
    \begin{block}{\huge Data Acquisition and Training}
\vspace{.5cm}

\begin{itemize}
\item Training data generated by automated players:
\begin{itemize} {\large
\item Player that chooses letters uniformly at random.
\item Player who chooses by frequency of appearance in a dictionary.}
\end{itemize}
\item Training based on calculating empirical conditional probabilities.
\end{itemize}

    \end{block}
   
\end{column}

\begin{column}{0.32\textwidth}
 
     \begin{block}{\huge Adversarial Word Selection}
\vspace{1cm}

{\Large How do we choose words that are difficult?}
\begin{itemize}
\item An adversarial word is a word on which the human loses with high probability. 

\item For a game with a maximum of $g$ incorrect guesses and a word of length $w$, 
{\large
\[
 \text{\# Incorrect Guess Scenarios} = \sum_{t = g}^{g+w-1}\binom{T}{g} = \frac{w}{g+1}\binom{g+w}{g}.
\]
}

\item Calculated only $\mathbb{P}[Y_1,\ldots,Y_g = 0]$, the probability that the human player never guesses correctly.
\end{itemize}

\vspace{1cm}

\begin{columns}
\begin{column}[b]{0.1\textwidth}
\end{column}
\begin{column}[b]{0.8\textwidth}

{\huge
\begin{alg}{{\large Adversarial Word Selection}}
\begin{enumerate}{\large
\item For each word $w$ in the dictionary:
\begin{enumerate} {\normalsize
\item Calculate $d_w =\mathbb{P}[Y_1, \ldots, Y_6 = 0\ |\ w]$ using the elimination algorithm, eliminating the $X_t$'s in the order $t = 6,5,\ldots, 1$.}
\end{enumerate}
\item Output $\hat w = \argmax_{w} d_w$.}
\end{enumerate}
\end{alg}}
\end{column}
\begin{column}[b]{0.1\textwidth}
\end{column}
\end{columns}

\vspace{.5cm}

\begin{figure}
\includegraphics[width=0.8\textwidth]{eliminationorderBoxed1.pdf}
\caption{The elimination order used to calculate the marginal probability $\mathbb{P}[Y_1,\ldots,Y_6 = 0 \ | \ \mathcal{W}]$ for word $\mathcal{W}$. Here we show steps 0, 2, 4, and 6.}
\end{figure}

    \end{block}

\vspace{1.5cm}

    \begin{block}{\huge Hardest Words Selected}

\vspace{.5cm}
\begin{itemize}
\item The words chosen by the adversary are hard,
\begin{itemize}{\large
\item But once you know theyre difficult it's easy to adjust.}
\end{itemize}
\item Top 12 words {\color{orange}(probability of losing in 6 turns)}:
\begin{multicols}{3}
\begin{enumerate}
\item by {\color{orange} (0.8356)}
\item gym {\color{orange} (0.8356)}
\item gyp {\color{orange} (0.8356)}
\item my {\color{orange} (0.8356)}
\item pygmy {\color{orange} (0.8356)}
\item pyx {\color{orange} (0.8356)}
\item wynd {\color{orange} (0.8333)}
\item wynn {\color{orange} (0.8333)}
\item hyp {\color{orange} (0.8274)}
\item why {\color{orange} (0.8274)}
\item hymn {\color{orange} (0.8252)}
\item nymph {\color{orange} (0.8252)}
\end{enumerate}
\end{multicols}
\item Some notable words from the hardest 500:
\begin{multicols}{3}
\begin{enumerate}
\item[25.] glyph {\color{orange} (0.7259)}
\item[42.] myrrh {\color{orange} (0.5928)}
\item[107.] rhythms  {\color{orange} (0.1316)}
\item[133.] fuzz  {\color{orange} (0.0059)}
\item[146.] kudzu {\color{orange} (0.0059)}
\item[231.] crumb {\color{orange} (0.0053)}
\item[284.] pudgy {\color{orange} (0.0048)}
\item[334.] busks {\color{orange} (0.0036)}
\item[489.] schmuck {\color{orange} (0.0034)}
\end{enumerate}
\end{multicols}
\end{itemize}

    \end{block}


\end{column}

\begin{column}{0.32\textwidth}

       \begin{block}{\huge Memory Parameter Selection}

\vspace{1cm}
{\Large Can the AI determine the correct memory of a player?}
\begin{itemize}
\item Generated data for players with restricted memory.
\begin{itemize} {\large
\item Extremely large number of samples required for AIC.
\item Can only implement model with memory parameters $1$ through $3$.}
\end{itemize}
\item Computed (corrected) AIC and BIC values
\begin{itemize} {\large
\item AIC consistently overestimates.
\item BIC consistently underestimates.}
\end{itemize}
\item Failure of AIC due to information available to player not captured by the model.
\end{itemize}

\vspace{1cm}

\begin{figure}
	\begin{subfigure}[b]{.45\textwidth}
\begin{center}
		\fbox{\includegraphics[width=\textwidth]{AICgraph.jpg}}
		\caption{AIC values.}
\end{center}
	\end{subfigure}
\hspace{1cm}
	\begin{subfigure}[b]{.45\textwidth}
\begin{center}
		\fbox{\includegraphics[width=\textwidth]{BICgraph.jpg}}
		\caption{BIC values.}
\end{center}
	\end{subfigure}
\hfill
	\caption{Plots of AIC and BIC Values against the Memory Parameter for a Dictionary Player with True Memory $2$}	
\end{figure}
    \end{block}

\vspace{1.5cm}

    \begin{block}{\huge Conclusion}

\vspace{1cm}
{\Large Achievements:}
\begin{itemize}
\item Can learn a player's strategy assuming restricted memory.
\item Can choose words that are hard for that player.
\item Compiled a list of hard words for a dictionary-using frequency player.
 \begin{itemize}{\large
\item  Also hard for regular humans.}
\end{itemize}
\end{itemize}

\vspace{.8cm}

{\Large Future Work:}
\begin{itemize} 
\item Online Learning.
\item Foiling an Adaptive Player.
\begin{itemize}{\large
\item  Can we learn an adaptive strategy quickly and counter it? 
\item Is there a Nash Equilibrium to the responses?}
\end{itemize}
\end{itemize}
\vspace{.5cm}
    \end{block}

\vspace{1.5cm}

    \begin{block}{\huge Acknowledgements}
We would like to thank:
\begin{itemize}
\item Martin Wainwright for guidance and advice.
\item UC Berkeley and the NSF for providing funds and resources.
\end{itemize}
    \end{block}
\end{column}

\end{columns}
\end{center}
\vspace{1.5cm}
  \end{frame}
  \end{document}
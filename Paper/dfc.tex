For testing and evaluation of our optimizer we implemented several variants of the DFC (Divide-Factor-Combine) framework for distributed matrix completion, originally introduced in \cite{Ameet}.

\subsection{DFC Framework Overview}
\subsubsection{Problem Definition}
The DFC framework is used to solve the following well-studied noisy matrix completion problem: Let $A$ be an unknown $m\times n$ matrix of rank $r$, and assume $r<<m,n$. Next $A'$ is obtained by adding a small amount of noise to every entry of $A$. Finally, a small fraction (e.g. $10\%$) of the entries of $A'$ are revealed. The goal is then to find a low-rank matrix $B$ that is a good approximation of the original matrix $A$, using only the revealed entries of $A'$. The standard method of finding such a low rank matrix $B$ is to find a low-rank factorization $B=UV^T$ that agrees with $A'$ on all the revealed entries.

A version of this problem is actually solved in practice by online movie-recommendation systems. Here the matrix has rows corresponding to users and columns corresponding to movies. The assumption that the matrix is low rank corresponds to the assumption that users movie preferences are only based on a relatively small number of factors (e.g. movie genre, movie length, user age etc).

\subsubsection{The DFC Algorithm}
The DFC framework for noisy matrix completion consists of three steps:
\begin{itemize}
\item \textbf{Divide} the input matrix $A$ column-wise into $k$ pieces $\{A_1,A_2,...A_k\}$. More specifically, $A_i$ consists of $n/k$ columns from $A$ and concatenating all the $A_i$ gives the original matrix $A$.
\item \textbf{Factor} each matrix $A_i$ as $U_i V_i^T$ ton a separate processor using some base matrix factorization algorithm.
\item \textbf{Combine} the factorizations $U_iV_i^T$ into one large factorization $UV^T$ using some matrix column projection algorithm.
\end{itemize}
From this description it is clear that there are several significant choices to be made in the implementation of this framework. First, both the base factorization algorithm and the projection algorithm for the combine step must be chosen. Second, the parameter $k$ for determining the number of slices to cut the matrix into has an impact both on runtime and accuracy of the result.

\subsection{Base Factorization Algorithm Choices}
We implemented two base matrix factorization algorithms: Stochastic Gradient Descent (SGD) and Accelerated Proximal Gradient Descent (APG). Both algorithms seek to minimize some objective function which is a combination of the error of the approximation and the rank of the factorization.
\subsubsection{Stochastic Gradient Descent}
Let $S$ be the set of indices for the revealed entries of the noisy matrix $A'$. The objective function for the Stochastic Gradient Descent algorithm is given by:
\[
F(U,V,A') = \sum_{(i,j)\in S} \left(A'_{ij} - (UV^T)_{ij}\right)^2 + \mu (\| U\|^2_F  + \| V\|^2_F)
\]
where $\|U\|_F$ denotes the Frobenius norm of $U$ and $\mu$ is a parameter. Intuitively, the first term in the objective function penalizes errors in matching the revealed entries of $A'$ and the second term is a regularization term to prevent over-fitting. The SGD algorithm uses standard gradient descent techniques to compute $\mbox{argmin}_{U,V} F(U,V,A')$. 

There are two important issues to note about the SGD algorithm. Firstly, the above minimization requires fixed choices for the dimensions of both $U$ and $V$. In particular, this means that we have to first decide on a rank $r$ for our factorization. Then we can run SGD to find a rank $r$ factorization that approximates $A'$ well. The second issue is that the objective function $F(U,V,A')$ is not convex, so there can be local minima where the SGD algorithm gets stuck.

\subsubsection{Accelerated Proximal Gradient Descent}
We use the Accelerated Proximal Gradient Descent algorithm described in \cite{APGPaper}. The objective function for the APG algorithm is given by:
\[
F(U,V,A') = {(i,j)\in S} \left(A'_{ij} - (UV^T)_{ij}\right)^2 + \mu \| UV^T\|_*
\]
where $\|UV^T\|_*$ is the nuclear norm of $UV^T$. The key point here is that the nuclear norm is a convex relaxation of the rank. This means that the above objective in some sense tries to minimize both the error in matching the revealed entries of $A'$, and some reasonable approximation of the rank of $B=UV^T$.

The algorithm has neither of the drawbacks of SGD. The user does not have to provide a guess for the rank, and the objective function is convex. Thus, the APG algorithm converges to a unique minimum, and there are theoretical guarantees on the convergence time.

\subsubsection{Base Algorithm Choice: APG}
We implemented both APG and SGD as described above, but it quickly became apparent that APG was superior for our purposes. The requirement that the user specify a rank for the factorization in SGD was a particularly large problem. First of all, having to specify a rank does not make a lot of sense when working with real-world data. For example, with a matrix of movie ratings it is not obvious apriori how many factors influence a user's movie preference. This is something that one would like the algorithm to do automatically, as APG does.

The second issue is that choosing the target rank of the factorization adds another parameter to the algorithm. Our optimizer uses data about the parameter settings of previous tasks to automatically choose parameters for a new task. As a result, the number of previous examples we need to cover the whole parameter space is exponential in the total number of parameters. So any additional parameter (such as the rank parameter to APG) greatly increases the number of examples required for the optimizer to preform well.

The fact that the SGD objective function is not convex also causes multiple issues in our setting. We observed empirically that there was much more variance in the runtime and accuracy of SGD based on the starting point. Since the objective is not convex, we had to simply run SGD until the improvement at each iteration got small enough. Since there are several local minima, this can result in quite different run times even on matrices from the same distribution. 

In comparison, APG has theoretical guarantees on its convergence, and we empirically observed that running for a fixed number of iterations on matrices from the same distribution resulted in relatively small variation in both error and runtime. This small variation is critical to the success of our optimizer in predicting the error and runtime of new matrix factorization tasks based on previous runs.
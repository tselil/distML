% !TeX root = 
Distributed matrix computations are essential in many big data 
applications. Algorithms for problems such as Noisy Matrix Factorization 
have applications in many areas such as recommender systems (i.e. Netflix),
succinct data storage, clustering, and more. For large matrices, these
algorithms quickly become computationally expensive, and it is necessary
to allocate computational resources (such as processors and amount of
time spent) wisely. In addition, these algorithms often take many input
parameters, and these parameters influence the accuracy of the outcome
or the total runtime. 

Though it is possible to determine the best parameters
empirically, this is both computationally expensive and prone to error. 
In addition, different datasets may respond differently to parameter
settings, and parameter settings that were good for a problem instance
may become suboptimal as time progresses and the input data changes.

In this work we describe a general system that, given an input problem, 
a distributed algorithm, and a computational budget, automates parameter 
choices for distributed matrix computations. We implement this optimizer,
focusing specifically on automating the choice of degree of parallelism. 
As a trial application, we use the optimizer on the Divide-Factor-Combine
algorithm (DFC), a recently-developed matrix factorization algorithm. 
We find that running the algorithm with the optimizer-chosen parameters 
yields errors that are as low as possible given the time and monetary 
budgets imposed.
